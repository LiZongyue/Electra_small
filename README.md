# Electra_small
Train a small Electra from scratch and fine tune it with GLUE.
## Install   

        $ pip install -r requirements.txt
        

## Train Electra from Scratch  
Before running the pre-training example, you should get a file that contains text on which the language model will be trained. A good example of such text is the [WikiText-2 dataset](https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/). Download WikiText.raw for the example.  


## Fine Tune the trained Electra_small with GLUE  
To be updated...
